{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaaranii12/emotion-analyzer/blob/main/Emotion_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIZVb2TJRblE"
      },
      "source": [
        "## Data Preparation & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT7iCXm2tAV1"
      },
      "outputs": [],
      "source": [
        "#Installing the Transformers library\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBY6hVUanJHm"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzpztHqi_3Zn"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "#Loading fine tuned model from Google Drive\n",
        "Roberta = \"/content/drive/MyDrive/Colab/Project1_Emotion_Analysis/finetuned_model\"\n",
        "\n",
        "#Roberta = \"j-hartmann/emotion-english-distilroberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(Roberta)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(Roberta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J4OFWNmYUad"
      },
      "source": [
        "Initially, the pre-trained checkpoint j-hartmann/emotion-english-distilroberta-base\n",
        " was used as a baseline. After fine-tuning on the dataset, the model and tokenizer were saved to Google Drive and are now loaded directly to save training time and ensure consistent results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyvFzbN6_TKA"
      },
      "outputs": [],
      "source": [
        "model.config.id2label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXFU9DZMMshG"
      },
      "source": [
        "**So, now we know the model supports 7 emotions:**\n",
        "\n",
        "0: anger ü§¨\n",
        "\n",
        "1: disgust ü§¢\n",
        "\n",
        "2: fear üò®\n",
        "\n",
        "3: joy üòÄ\n",
        "\n",
        "4: neutral üòê\n",
        "\n",
        "5: sadness üò≠\n",
        "\n",
        "6: surprise üò≤"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIQw9_P-ZIHg"
      },
      "source": [
        "### Dataset 1: Emotions by Nidula Elgiriyewithana (2023)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8YijOcmLVBC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#Loading of dataset\n",
        "dataset1 = pd.read_csv('/content/drive/MyDrive/Colab/Project1_Emotion_Analysis/Emotions.csv', encoding='latin-1', on_bad_lines='skip', quoting=3)\n",
        "dataset1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13-PBldnRMZt"
      },
      "outputs": [],
      "source": [
        "#Drop unnecessary columns\n",
        "dataset1 = dataset1.drop(columns=[\"Unnamed: 0\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEHsFNZYLauS"
      },
      "outputs": [],
      "source": [
        "print(dataset1.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62jBuX8POg1l"
      },
      "source": [
        "Drop all data labeled love [2] because the model doesn‚Äôt support & it roughly corresponds to joy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m91FDzr5B29G"
      },
      "outputs": [],
      "source": [
        "dataset1 = dataset1[dataset1[\"label\"] != 2].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JYdF_qIXwOR"
      },
      "outputs": [],
      "source": [
        "#Map the labels to their corresponding emotions.\n",
        "label_mapping = {0: 'sadness', 1: 'joy', 3: 'anger', 4: 'fear', 5: 'surprise'}\n",
        "dataset1['emotion'] = dataset1['label'].map(label_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rqYHUcICKTL"
      },
      "outputs": [],
      "source": [
        "print(dataset1.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeqZPqgePmZG"
      },
      "source": [
        "The dataset‚Äôs label IDs don‚Äôt match the model‚Äôs expected IDs, and each emotion maps differently. To avoid confusion we remap the labels to align with the model‚Äôs configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHalj_JbCbwY"
      },
      "outputs": [],
      "source": [
        "#Dataset to model label mapping\n",
        "remap = {\n",
        "    0: 5, #Sadness\n",
        "    1: 3, #Joy\n",
        "    3: 0, #Anger\n",
        "    4: 2, #Fear\n",
        "    5: 6  #Surprise\n",
        "}\n",
        "\n",
        "#Remapping the labels\n",
        "dataset1[\"label\"] = dataset1[\"label\"].map(remap)\n",
        "dataset1 = dataset1.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVfPelmJDu8y"
      },
      "outputs": [],
      "source": [
        "print(dataset1.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhxz8NKJZjwb"
      },
      "source": [
        "### Dataset 2: Go Emotions by Shivam Bansal (2021)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lACIs8T474Br"
      },
      "outputs": [],
      "source": [
        "#Loading of dataset\n",
        "dataset2 = pd.read_csv('/content/drive/MyDrive/Colab/Project1_Emotion_Analysis/GoEmotions.csv', encoding='latin-1', on_bad_lines='skip', quoting=3, low_memory=False)\n",
        "dataset2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eERoOB7o8SqD"
      },
      "outputs": [],
      "source": [
        "print(dataset2.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti3Ev_QXDf-B"
      },
      "source": [
        "The original dataset has multiple columns indicating different emotions with 0/1 values. A single label column is created to summarize the dominant emotion for each text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kW1ckh5L9TY9"
      },
      "outputs": [],
      "source": [
        "#The emotions supported by the model, in it's label's order\n",
        "main_emotions = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n",
        "\n",
        "#Assigning label\n",
        "def assign_label(row):\n",
        "    for i, col in enumerate(main_emotions):\n",
        "        if row[col] == 1:\n",
        "            return i\n",
        "    #Assign 7 for emotions other than the main 6\n",
        "    return 7\n",
        "\n",
        "dataset2['label'] = dataset2.apply(assign_label, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHh_nAlYGKr-"
      },
      "outputs": [],
      "source": [
        "#mapping the labels (easier referencing)\n",
        "label_map = {0: 'anger', 1: 'disgust', 2: 'fear', 3: 'joy', 4: 'neutral', 5: 'sadness', 6: 'surprise'}\n",
        "dataset2['emotion'] = dataset2['label'].map(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUzyRJq-BTDZ"
      },
      "outputs": [],
      "source": [
        "#Drop all rows that has the label 7 (other emotions)\n",
        "dataset2 = dataset2[dataset2['label'] != 7].reset_index(drop=True)\n",
        "\n",
        "#Drop all other unnecessary columns\n",
        "dataset2 = dataset2[['text', 'label', 'emotion']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-4bhEJG9jI0"
      },
      "outputs": [],
      "source": [
        "print(dataset2.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l-1bmuqFunm"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    #Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    #Remove placeholders like [NAME], [RELIGION], etc.\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "\n",
        "    #Remove common social media tokens like /s, /jk, <3\n",
        "    text = re.sub(r'/s|/jk|<3', '', text)\n",
        "\n",
        "    #Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    #Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "#Apply to the dataframe\n",
        "dataset2['text'] = dataset2['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1040ajMhSbSs"
      },
      "source": [
        "###Train-Test Split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZctzIrLYIEVt"
      },
      "source": [
        "Combining both dataset 1 and dataset 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaNZl2HcIKX2"
      },
      "outputs": [],
      "source": [
        "data = pd.concat([dataset1, dataset2], ignore_index=True)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GV4rfbYKubU"
      },
      "outputs": [],
      "source": [
        "#Deduplicating data before splitting to avoid overlapping texts\n",
        "data = data.drop_duplicates(subset=['text']).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHKac6gxUNBc"
      },
      "source": [
        "The dataset has 450K+ rows, which is too large for quick fine-tuning. To speed things up, we limit it to 20,000 rows with an equal number of samples per label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ree5usxJGduB"
      },
      "outputs": [],
      "source": [
        "#Perform stratified sampling to take an equal number of rows from each label.\n",
        "n_per_class = 10000 // data[\"label\"].nunique()\n",
        "data = data.groupby(\"label\", group_keys = False).apply(lambda x: x.sample(n = n_per_class, random_state = 42))\n",
        "\n",
        "print(data[\"label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTho2VttHeOO"
      },
      "outputs": [],
      "source": [
        "#Get the number of unique emotions in the dataset\n",
        "num_labels = data[\"label\"].nunique()\n",
        "print(f\"Number of unique emotions: {num_labels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQPPpt4XUT6V"
      },
      "source": [
        "We split the dataset into training and test sets (80/20 - according to the\n",
        "Pareto theory) so the model can learn from one portion and be fairly evaluated on unseen data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQcLj-53H1L7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Stratified splitting of dataset\n",
        "train_data, test_data = train_test_split(data, test_size = 0.2, stratify = data[\"label\"], random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TayJmwZWIrNQ"
      },
      "outputs": [],
      "source": [
        "print(\"Train data distribution:\\n\", train_data[\"label\"].value_counts())\n",
        "print(\"\\nTest data distribution:\\n\", test_data[\"label\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViTIGPBJWOr4"
      },
      "source": [
        "**Data leakage** is when information from the test set ‚Äúleaks‚Äù into the training set, meaning the model accidentally sees data it shouldn‚Äôt during training. This makes the test accuracy look higher than reality because the model didn‚Äôt have to generalize, it just memorized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0GGYnPJIv6v"
      },
      "outputs": [],
      "source": [
        "#Check to see if there's any overlapping texts (data leaks)\n",
        "overlapping_texts = set(train_data[\"text\"]).intersection(set(test_data[\"text\"]))\n",
        "print(\"Number of overlapping texts:\", len(overlapping_texts))\n",
        "\n",
        "#Drop overlaps directly from train_data and test_data to avoid data leakage\n",
        "#train_data = train_data[~train_data[\"text\"].isin(overlapping_texts)].reset_index(drop=True)\n",
        "#test_data = test_data[~test_data[\"text\"].isin(overlapping_texts)].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMV-u4ijWzqt"
      },
      "source": [
        "## Model Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNorOAymNYjT"
      },
      "outputs": [],
      "source": [
        "#Coverting pandas DataFrame into a Hugging Face Dataset\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "train_hf = Dataset.from_pandas(train_data)\n",
        "test_hf = Dataset.from_pandas(test_data)\n",
        "\n",
        "data = DatasetDict({\n",
        "    \"train\": train_hf,\n",
        "    \"test\": test_hf\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOxgKHHfQhxA"
      },
      "source": [
        "**Tokenization** turns text into numbers the model understands. This is important because models like RoBERTa cannot read raw text and only work with numerical tokens to learn patterns and make predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_c4-gRTD3kL"
      },
      "outputs": [],
      "source": [
        "def tokenize(dataset):\n",
        "    return tokenizer(dataset [\"text\"], padding=True, truncation=True, max_length=128)\n",
        "\n",
        "data = data.map(tokenize, batched=True)\n",
        "train_hf = train_hf.map(tokenize, batched=True)\n",
        "test_hf = test_hf.map(tokenize, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZ9jLaUGLoLA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics_function(prediction):\n",
        "    labels = prediction.label_ids\n",
        "    predictions = prediction.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average = 'weighted')\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79BaDUa2MO5m"
      },
      "outputs": [],
      "source": [
        "def model_init():\n",
        "  return AutoModelForSequenceClassification.from_pretrained(Roberta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afknumP4L2-N"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "#Set the training arguments\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir = \"./results\",\n",
        "    eval_strategy = \"epoch\",\n",
        "    per_device_train_batch_size = 16,\n",
        "    per_device_eval_batch_size = 16,\n",
        "    num_train_epochs = 3,\n",
        "    learning_rate = 2e-5,\n",
        "    weight_decay = 0.01\n",
        ")\n",
        "\n",
        "#Construct the trainer\n",
        "trainer = Trainer (\n",
        "    model_init = model_init,\n",
        "    args = training_arguments,\n",
        "    train_dataset = data[\"train\"],\n",
        "    eval_dataset = data[\"test\"],\n",
        "    tokenizer = tokenizer,\n",
        "    compute_metrics = compute_metrics_function\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuNzW1T2W0uO"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGEH_VKeXE4Y"
      },
      "outputs": [],
      "source": [
        "# Save into Google Drive\n",
        "model.save_pretrained(\"/content/drive/MyDrive/Colab/Project1_Emotion_Analysis/finetuned_model\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/Colab/Project1_Emotion_Analysis/finetuned_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_KF6EzRa7I9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Get the model predictions on the test set\n",
        "results = trainer.predict(data[\"test\"])\n",
        "\n",
        "#Extract predicted and true labels\n",
        "predicted = results.predictions.argmax(-1) #argmax pick class with highest probability\n",
        "labels = results.label_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BAL6rgfZgeb"
      },
      "outputs": [],
      "source": [
        "# Define label names for better clarity in the confusion matrix\n",
        "label_names = [\"anger\", \"disgust\", \"fear\", \"joy\", \"neutral\", \"sadness\", \"surprise\"]\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cmx = confusion_matrix(labels, predicted)\n",
        "\n",
        "# Plot out the confusion matrix\n",
        "plt.figure(figsize = (10, 10))\n",
        "sns.heatmap(cmx, annot = True, fmt = 'd', xticklabels = label_names, yticklabels = label_names, cmap = \"pink\")\n",
        "\n",
        "#Add labels\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Initial Training Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(cmx)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deployment to Gradio"
      ],
      "metadata": {
        "id": "L40dXfL9oO8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fine-tuned emotion analysis model was deployed on Hugging Face by uploading it to the Model Hub and linking it with a Space."
      ],
      "metadata": {
        "id": "yyWLL1rANZrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "WvF7iuMTfgkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U huggingface_hub"
      ],
      "metadata": {
        "id": "KggGXwIah8K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Hugging Face Hub functions for authentication and uploading\n",
        "from huggingface_hub import login, create_repo, upload_folder\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
      ],
      "metadata": {
        "id": "M6-l14_biBhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Log in to Hugging Face Hub and authenticate with tokens\n",
        "login()"
      ],
      "metadata": {
        "id": "7-M3IDyJiC5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the repository ID\n",
        "repo_id = \"Shaaranii12/emotion-analysis-model\"\n",
        "\n",
        "#Create a new repository on Hugging Face Hub\n",
        "create_repo(repo_id=repo_id, repo_type=\"model\", private=False, exist_ok=True)\n",
        "print(\"Repo created at:\", \"https://huggingface.co/\" + repo_id)"
      ],
      "metadata": {
        "id": "i4GoF-6piKZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   repo_type=\"model\" means this is a model repo, not a dataset or Space\n",
        "2.   private=False makes it public so your Space can access it\n",
        "3. exist_ok=True means create repo if it doesn't exist, otherwise do nothing to throw off error warning"
      ],
      "metadata": {
        "id": "FHidg5iuMMpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#uploading the trained fine tuned model\n",
        "local_model_path = \"/content/drive/MyDrive/Colab/Project1_Emotion_Analysis/finetuned_model\"\n",
        "\n",
        "upload_folder(\n",
        "    repo_id=\"Shaaranii12/emotion-analysis-model\",  # your repo\n",
        "    folder_path=local_model_path,\n",
        "    path_in_repo=\".\",   # upload into root of repo\n",
        "    commit_message=\"Upload fine-tuned RoBERTa emotion model\"\n",
        ")\n",
        "\n",
        "#https://huggingface.co/spaces/Shaaranii12/emotion-analyzer"
      ],
      "metadata": {
        "id": "XTeVf2fujI-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model was successfully uploaded and deployed on Hugging Face Spaces, creating a simple web app where users can input text and see the predicted emotion.\n",
        "\n",
        "Click the link to explore the app: [Emotions Analyzer](https://huggingface.co/spaces/Shaaranii12/emotion-analyzer)"
      ],
      "metadata": {
        "id": "zJUESoBoNmhe"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "AIQw9_P-ZIHg"
      ],
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyP7gQwCRQMJs6FchXGNo19u",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}